{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "-DWnR_eC-3QD",
        "outputId": "59726cb4-d11e-4f1a-a781-038aac6933b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries installed and ready.\n",
            "‚úÖ Demo files created in demo_data/\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-089b4828-6eb5-4804-9a3c-1787f760ab4c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-089b4828-6eb5-4804-9a3c-1787f760ab4c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving V_S_Sruthi_Resume_ATS_v2 (1).pdf to V_S_Sruthi_Resume_ATS_v2 (1).pdf\n",
            "‚úÖ Uploaded files moved to demo_data/\n",
            "üìÅ Files processed: ['demo_img.jpg', 'demo_pdf.pdf', 'V_S_Sruthi_Resume_ATS_v2 (1).pdf', 'demo_text.txt', 'demo_ppt.pptx', 'demo_doc.docx']\n",
            "‚úÖ LLM ready for interactive queries.\n",
            "\n",
            "ü§ñ LLM Answer:\n",
            " Sruthi has over 9 years of experience.\n",
            "\n",
            "ü§ñ LLM Answer:\n",
            " None\n",
            "\n",
            "ü§ñ LLM Answer:\n",
            " None\n",
            "\n",
            "ü§ñ LLM Answer:\n",
            " Sruthi passed out with a B.Tech in 2015.\n",
            "\n",
            "ü§ñ LLM Answer:\n",
            " None\n",
            "\n",
            "ü§ñ LLM Answer:\n",
            " V. S. Sruthi's resume mentions the following technical skills:\n",
            "*   **Programming:** ITIS Basics, Linux Administration, OOP Concepts, HTML\n",
            "*   **Operating Systems:** Windows 2000/XP/7/10\n",
            "*   **Database:** SQL\n",
            "*   **Frameworks:** ITIL (Incident, Problem & Change Management)\n",
            "*   **Tools:** ServiceNow, PuTTY, JIRA, Google Internal Tools\n",
            "\n",
            "ü§ñ LLM Answer:\n",
            " I state \"None\" when the requested information is not present in the documents I am given.\n",
            "\n",
            "ü§ñ LLM Answer:\n",
            " Yes, information about Sruthi's current employment is present. She is currently a Technical Lead at Cognizant Technology Solutions, working with the client Google, a role she has held since June 2018.\n"
          ]
        }
      ],
      "source": [
        "# =========================================================\n",
        "# Multimodal Data Processing & LLM Q&A (One-Cell Demo)\n",
        "# FIXES:\n",
        "# 1. Corrected types.Part creation from .from_text() to Part(text=...).\n",
        "# 2. Added try...finally block for explicit client cleanup to avoid AttributeError.\n",
        "# =========================================================\n",
        "# 1Ô∏è‚É£ Install libraries\n",
        "!pip install --quiet pdfplumber python-docx python-pptx pillow pytesseract sentence-transformers google-genai fpdf yt-dlp\n",
        "\n",
        "import os\n",
        "from docx import Document\n",
        "from pptx import Presentation\n",
        "from fpdf import FPDF\n",
        "from PIL import Image, ImageDraw\n",
        "import pdfplumber\n",
        "import pytesseract\n",
        "from google import genai\n",
        "from google.genai import types # Import types for configuration\n",
        "import getpass\n",
        "\n",
        "print(\"‚úÖ Libraries installed and ready.\")\n",
        "\n",
        "# 2Ô∏è‚É£ Create demo folder & files\n",
        "os.makedirs(\"demo_data\", exist_ok=True)\n",
        "\n",
        "# TXT\n",
        "with open(\"demo_data/demo_text.txt\", \"w\") as f:\n",
        "    f.write(\"This is a sample TXT file. Sruthi has 5 years of experience in data science. She worked at two companies.\")\n",
        "\n",
        "# DOCX\n",
        "doc = Document()\n",
        "doc.add_heading(\"Demo Document\", 0)\n",
        "doc.add_paragraph(\"This is a sample DOCX document. John is a software engineer with 3 years of experience.\")\n",
        "doc.save(\"demo_data/demo_doc.docx\")\n",
        "\n",
        "# PDF\n",
        "pdf = FPDF()\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", size=12)\n",
        "pdf.cell(200, 10, txt=\"This is a sample PDF file. The project budget is $50,000.\", ln=True)\n",
        "pdf.output(\"demo_data/demo_pdf.pdf\")\n",
        "\n",
        "# PPTX\n",
        "ppt = Presentation()\n",
        "slide = ppt.slides.add_slide(ppt.slide_layouts[5])\n",
        "slide.shapes.title.text = \"Demo PPT Slide\"\n",
        "ppt.save(\"demo_data/demo_ppt.pptx\")\n",
        "\n",
        "# IMAGE\n",
        "img = Image.new('RGB', (300, 100), color=(73, 109, 137))\n",
        "d = ImageDraw.Draw(img)\n",
        "d.text((10,40), \"Demo Image Text\", fill=(255,255,0))\n",
        "img.save(\"demo_data/demo_img.jpg\")\n",
        "\n",
        "print(\"‚úÖ Demo files created in demo_data/\")\n",
        "\n",
        "# 3Ô∏è‚É£ Optional: Upload your own files\n",
        "# NOTE: This part relies on the Google Colab environment.\n",
        "try:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        os.rename(filename, os.path.join(\"demo_data\", filename))\n",
        "    if uploaded:\n",
        "        print(\"‚úÖ Uploaded files moved to demo_data/\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Skipping file upload. Not running in Google Colab environment.\")\n",
        "\n",
        "\n",
        "# 4Ô∏è‚É£ Parse all files\n",
        "file_contents = {}\n",
        "\n",
        "def parse_pdf(path):\n",
        "    text=[]\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text.append(page.extract_text() or \"\")\n",
        "    return \"\\n\".join(text)\n",
        "\n",
        "def parse_docx(path):\n",
        "    doc = Document(path)\n",
        "    return \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
        "\n",
        "def parse_pptx(path):\n",
        "    prs = Presentation(path)\n",
        "    texts=[]\n",
        "    for slide in prs.slides:\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape,\"text\"):\n",
        "                texts.append(shape.text)\n",
        "    return \"\\n\".join(texts)\n",
        "\n",
        "def parse_txt(path):\n",
        "    return open(path).read()\n",
        "\n",
        "def parse_image(path):\n",
        "    # This function uses Pytesseract for OCR\n",
        "    return pytesseract.image_to_string(Image.open(path))\n",
        "\n",
        "for f in os.listdir(\"demo_data\"):\n",
        "    path = os.path.join(\"demo_data\", f)\n",
        "    if f.endswith(\".pdf\"): file_contents[f] = parse_pdf(path)\n",
        "    elif f.endswith(\".docx\"): file_contents[f] = parse_docx(path)\n",
        "    elif f.endswith(\".pptx\"): file_contents[f] = parse_pptx(path)\n",
        "    elif f.endswith(\".txt\"): file_contents[f] = parse_txt(path)\n",
        "    elif f.endswith((\".jpg\",\".png\")): file_contents[f] = parse_image(path)\n",
        "\n",
        "print(\"üìÅ Files processed:\", list(file_contents.keys()))\n",
        "\n",
        "# 5Ô∏è‚É£ LLM Setup (GEMINI API)\n",
        "\n",
        "# Get API key securely\n",
        "try:\n",
        "    API_KEY = getpass.getpass(\"Enter your Gemini API Key: \")\n",
        "    if not API_KEY:\n",
        "        raise ValueError(\"API Key cannot be empty.\")\n",
        "    client = genai.Client(api_key=API_KEY)\n",
        "except (ImportError, ValueError) as e:\n",
        "    print(f\"‚ùå Error setting up client: {e}. Please ensure you are running in an environment that supports getpass or set the GEMINI_API_KEY environment variable.\")\n",
        "    client = None\n",
        "\n",
        "if client:\n",
        "    print(\"‚úÖ LLM ready for interactive queries.\")\n",
        "\n",
        "# 6Ô∏è‚É£ Interactive LLM Q&A\n",
        "def ask_llm(question, context_texts):\n",
        "    context_combined = \"\\n\\n\".join([f\"--- {fname} ---\\n{txt}\" for fname, txt in context_texts.items()])\n",
        "\n",
        "    # Construct the full prompt including System Instruction and User Question\n",
        "    prompt_parts = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                # *** CORRECTED SYNTAX: Used Part(text=...) instead of Part.from_text(...) ***\n",
        "                types.Part(text=f\"\"\"\n",
        "You are an intelligent assistant. Answer the user's question based ONLY on the following documents.\n",
        "If the information is not present, state that clearly.\n",
        "\n",
        "--- DOCUMENTS START ---\n",
        "{context_combined}\n",
        "--- DOCUMENTS END ---\n",
        "\n",
        "Question: {question}\n",
        "Answer in short, precise, and natural language.\n",
        "\"\"\")\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Configuration for the generation\n",
        "    config = types.GenerateContentConfig(\n",
        "        temperature=0.3,\n",
        "        max_output_tokens=500\n",
        "    )\n",
        "\n",
        "    # Gemini API Call\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\", # A great, fast model for chat and RAG\n",
        "        contents=prompt_parts,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    return response.text\n",
        "\n",
        "# Main loop execution with robust cleanup\n",
        "if client:\n",
        "    try:\n",
        "        while True:\n",
        "            q = input(\"\\nüí¨ Ask a question (e.g., 'How much experience does Sruthi have?' or type 'exit'): \")\n",
        "            if q.lower()==\"exit\":\n",
        "                print(\"üëã Exiting demo.\")\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                answer = ask_llm(q, file_contents)\n",
        "                print(\"\\nü§ñ LLM Answer:\\n\", answer)\n",
        "            except Exception as e:\n",
        "                # Catch specific API errors during content generation\n",
        "                print(f\"\\n‚ùå An error occurred during API call: {e}\")\n",
        "\n",
        "    finally:\n",
        "        # Explicitly close the client to avoid the 'AttributeError' cleanup warning\n",
        "        client.close()\n",
        "        print(\"\\n‚úÖ Gemini Client explicitly closed and resources released.\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Cannot run Q&A. Client failed to initialize.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}